= EFK
ElasticSearch/FileBeat/Kibana
:sectnums:
:chapter-signifier: 章节
:scripts: cjk
:toc:
:toc-title: 目录
:toclevels: 3
:doctype: book
:experimental:

== ElasticSearch 与 Kibana
=== https://www.elastic.co/guide/en/elasticsearch/reference/8.14/docker.html#docker-prod-prerequisites[官方参考^]

=== 在Swarm Manager上进行
==== 创建目录
[source,bash]
----
mkdir -p /usr/local/elasticsearch/
chmod 775 -R /usr/local/elasticsearch/
----

==== 利用临时容器初始化所需文件
. 创建并运行临时容器
+
[source,bash]
----
docker run --rm -it --net=rebue docker.elastic.co/elasticsearch/elasticsearch:8.14.2 bash
----
. 进入容器内初始化
+
https://github.com/elastic/elasticsearch/blob/8.14/docs/reference/setup/install/docker/docker-compose.yml[官方参考^]
+

[source,bash]
----
# 安装ik中文分词插件
bin/elasticsearch-plugin install https://get.infini.cloud/elasticsearch/analysis-ik/8.14.2
# 安装pinyin插件
bin/elasticsearch-plugin install https://get.infini.cloud/elasticsearch/analysis-pinyin/8.14.2

# 生成CA证书并解压
bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
unzip config/certs/ca.zip -d config/certs;
# 生成数字证书
echo -ne \
          "instances:\n"\
          "  - name: es01\n"\
          "    dns:\n"\
          "      - es01\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: es02\n"\
          "    dns:\n"\
          "      - es02\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: es03\n"\
          "    dns:\n"\
          "      - es03\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
unzip config/certs/certs.zip -d config/certs;
# 修改数字证书的访问权限
#chown -R root:root config/certs;
#find . -type d -exec chmod 750 \{\} \;;
#find . -type f -exec chmod 640 \{\} \;;

----

. 将config和plugins目录复制到宿主机上(在宿主机上进行)
+
[source,bash]
----
docker cp <容器ID>:/usr/share/elasticsearch/config/ /usr/local/elasticsearch/
docker cp <容器ID>:/usr/share/elasticsearch/plugins/ /usr/local/elasticsearch/
----

=== 在所有ES宿主机上进行
==== 同步目录
同步 Swarm Manager 的 /usr/local/elasticsearch/ 目录到每台ES宿主机

==== 创建目录并配置目录可读写
ElasticSearch 在容器中运行的用户是 `elasticsearch`，`uid:gid` 是 `1000:0`
https://www.elastic.co/guide/en/elasticsearch/reference/8.14/docker.html#_configuration_files_must_be_readable_by_the_elasticsearch_user[官方参考^]

[source,bash]
----
mkdir -p /var/lib/elasticsearch/data
mkdir -p /var/lib/kibana/data/
mkdir -p /var/log/elasticsearch/
chmod g+rwx -R /usr/local/elasticsearch/config
chmod g+rwx -R /usr/local/elasticsearch/plugins
chmod g+rwx -R /var/lib/elasticsearch/data
chmod g+rwx -R /var/lib/kibana/data
chmod g+rwx -R /var/log/elasticsearch/
chgrp 0 -R /usr/local/elasticsearch/config
chgrp 0 -R /usr/local/elasticsearch/plugins
chgrp 0 -R /var/lib/elasticsearch/data
chgrp 0 -R /var/lib/kibana/data
chgrp 0 -R /var/log/elasticsearch/
----

==== 设置 `vm.max_map_count` 不小于 `262144`
* 临时生效
+
[source,bash]
----
sysctl -w vm.max_map_count=262144
----
* 永久生效
+
./etc/sysctl.conf
[source,bash]
----
....
vm.max_map_count=262144
....
----

==== 禁用交换
https://www.elastic.co/guide/en/elasticsearch/reference/8.14/docker.html#_disable_swapping[官方参考^]

* 临时生效
+
[source,bash]
----
swapoff -a
----
* 永久生效
+
./etc/sysctl.conf
[source,bash]
----
....
# 禁用内存交换
vm.swappiness=1
....
----

=== 在所有Kibana宿主机上进行

==== 同步目录
同步 Swarm Manager 的 /usr/local/elasticsearch/ 目录到每台Kibana宿主机

==== 创建目录并配置目录可读写
ElasticSearch 在容器中运行的用户是 `elasticsearch`，`uid:gid` 是 `1000:0`
https://www.elastic.co/guide/en/elasticsearch/reference/8.14/docker.html#_configuration_files_must_be_readable_by_the_elasticsearch_user[官方参考^]

[source,bash]
----
mkdir -p /var/lib/kibana/data/
chmod 775 -R /var/lib/kibana/data/
----

=== 部署(在Swarm Manager上进行)
. https://github.com/elastic/elasticsearch/blob/8.14/docs/reference/setup/install/docker/.env[.env官方参考^]
. https://github.com/elastic/elasticsearch/blob/8.14/docs/reference/setup/install/docker/docker-compose.yml[docker-compose.yml官方参考^]
. 准备部署的环境变量文件
+

./usr/local/elasticsearch/.env
[source,ini]
----
# network name
NETWORK_NAME=rebue

# kibana node name
KIBANA_NODE_NAME=kibana

# Password for the 'elastic' user (at least 6 characters)
ELASTIC_PASSWORD=xxxxxxxx

# Password for the 'kibana_system' user (at least 6 characters)
KIBANA_PASSWORD=xxxxxxxx

# Version of Elastic products
STACK_VERSION=8.14.2

# Set the cluster name
CLUSTER_NAME=es

# Set to 'basic' or 'trial' to automatically start the 30-day trial
LICENSE=basic
#LICENSE=trial

# Port to expose Elasticsearch HTTP API to the host
ES_PORT=9200
#ES_PORT=127.0.0.1:9200

# Port to expose Kibana to the host
KIBANA_PORT=5601
#KIBANA_PORT=80

# Increase or decrease based on the available host memory (in bytes)
MEM_LIMIT=1G

# Project namespace (defaults to the current folder name if not set)
#COMPOSE_PROJECT_NAME=myproject
----
. 准备部署配置的模板文件
+
./usr/local/elasticsearch/stack.yml.tpl
[source,yaml]
----
version: "3.9"
services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    hostname: es01
    volumes:
      - /usr/local/elasticsearch/config/:/usr/share/elasticsearch/config/
      - /usr/local/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/
      - /var/lib/elasticsearch/data/:/usr/share/elasticsearch/data/
      - /var/log/elasticsearch/:/usr/share/elasticsearch/logs/
    # ports:
    #   - ${ES_PORT}:9200
    environment:
      - node.name=es01
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01,es02,es03
      - discovery.seed_hosts=es02,es03
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es01/es01.key
      - xpack.security.http.ssl.certificate=certs/es01/es01.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es01/es01.key
      - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    #  - ES_JAVA_OPTS="-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65535
        hard: 65535
    deploy:
      resources:
        limits:
          memory: ${MEM_LIMIT}
      placement:
        constraints:
          - node.hostname==es01
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    logging:
      options:
        max-size: 8m

  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    hostname: es02
    volumes:
      - /usr/local/elasticsearch/config/:/usr/share/elasticsearch/config/
      - /usr/local/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/
      - /var/lib/elasticsearch/data/:/usr/share/elasticsearch/data/
      - /var/log/elasticsearch/:/usr/share/elasticsearch/logs/
    environment:
      - node.name=es02
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01,es02,es03
      - discovery.seed_hosts=es01,es03
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es02/es02.key
      - xpack.security.http.ssl.certificate=certs/es02/es02.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es02/es02.key
      - xpack.security.transport.ssl.certificate=certs/es02/es02.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    #  - ES_JAVA_OPTS="-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    deploy:
      resources:
        limits:
          memory: ${MEM_LIMIT}
      placement:
        constraints:
          - node.hostname==es02
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    logging:
      options:
        max-size: 8m

  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    hostname: es03
    volumes:
      - /usr/local/elasticsearch/config/:/usr/share/elasticsearch/config/
      - /usr/local/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/
      - /var/lib/elasticsearch/data/:/usr/share/elasticsearch/data/
      - /var/log/elasticsearch/:/usr/share/elasticsearch/logs/
    environment:
      - node.name=es03
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01,es02,es03
      - discovery.seed_hosts=es01,es02
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es03/es03.key
      - xpack.security.http.ssl.certificate=certs/es03/es03.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es03/es03.key
      - xpack.security.transport.ssl.certificate=certs/es03/es03.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    #  - ES_JAVA_OPTS="-Xms1g -Xmx1g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    deploy:
      resources:
        limits:
          memory: ${MEM_LIMIT}
      placement:
        constraints:
          - node.hostname==es03
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    logging:
      options:
        max-size: 8m

  kibana:
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    volumes:
      - /usr/local/elasticsearch/config/certs/:/usr/share/kibana/config/certs
      - /var/lib/kibana/data/:/usr/share/kibana/data
    #ports:
    #  - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=["https://es01:9200","https://es02:9200","https://es03:9200"]
      - SERVER_BASEPATH=/kibana
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
    deploy:
      placement:
        constraints:
          - node.labels.role==${KIBANA_NODE_ROLE}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
    logging:
      options:
        max-size: 8m

networks:
  default:
    external: true
    name: ${NETWORK_NAME}
----

. 通过模板生成部署配置文件
** envsubst方式
.. 安装 envsubst
+
[source,bash]
----
yum install -y gettext
----
.. 生成部署配置文件
+
[source,bash]
----
# 读取环境变量
source /usr/local/elasticsearch/.env
# 注入部署配置文件
envsubst < /usr/local/elasticsearch/stack.yml.tpl > /usr/local/elasticsearch/stack.yml
----
** envsubst.py方式
.. https://www.cnblogs.com/leoninew/p/13516223.html[参考^]
.. 代码
+
[source,python]
----
include::envsubst.py[]
----
.. 生成部署配置文件
+
[source,bash]
----
python3 /usr/local/elasticsearch/envsubst.py --env-file /usr/local/elasticsearch/.env -f /usr/local/elasticsearch/stack.yml.tpl > /usr/local/elasticsearch/stack.yml
----

. 部署
+
[source,bash]
----
docker stack deploy -c /usr/local/elasticsearch/stack.yml es
----

=== 在ES中添加kibana访问的账户和密码(在临时容器中进行)
. 创建并运行临时容器
+
[source,bash]
----
docker run --rm -it --net=rebue --env-file /usr/local/elasticsearch/.env \
-v /usr/local/elasticsearch/config/certs/:/usr/share/elasticsearch/config/certs/ \
docker.elastic.co/elasticsearch/elasticsearch:8.14.2 bash
----
. 进入容器内添加kibana访问的账户和密码
+
https://github.com/elastic/elasticsearch/blob/8.14/docs/reference/setup/install/docker/docker-compose.yml[官方参考^]
+

[source,bash]
----
# 在ES中添加kibana访问的账户和密码(下面的执行要等es部署好后再运行)
curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}"
----

== FileBeat
=== 官方参考
* https://www.elastic.co/guide/en/beats/filebeat/current/running-on-docker.html[在docker中运行FileBeat^]
* https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-reference-yml.html[配置文件^]
* https://www.elastic.co/guide/en/beats/filebeat/current/securing-communication-elasticsearch.html[与ElasticSearch安全通讯^]

=== 在ES中添加filebeat通讯所需内容(在临时容器中进行)
. 创建并运行临时容器
+
[source,bash]
----
docker run --rm -it --net=rebue --env-file /usr/local/elasticsearch/.env \
-v /usr/local/elasticsearch/config/certs/:/usr/share/elasticsearch/config/certs/ \
docker.elastic.co/elasticsearch/elasticsearch:8.14.2 bash
----
. 进入容器内执行下面内容(要等ES部署好后再运行)
+

[source,bash]
----
# 在ES中添加filebeat访问所需的API_KEY(注意修改里面的rebue-*改为实际的名称)
curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/api_key -d "{\"name\":\"filebeat_system\",\"role_descriptors\":{\"filebeat_writer\":{\"cluster\":[\"monitor\",\"read_ilm\",\"read_pipeline\"],\"index\":[{\"names\":[\"filebeat-*\",\"rebue-*\"],\"privileges\":[\"view_index_metadata\",\"create_doc\",\"auto_configure\"]}]}}}"

# ....
# 记录上面返回的id和api_key，字符串格式为 `id:api_key`，后面的配置要用
# ....

# 在ES中添加名为rebue的pipeline(这里的rebue可以根据实际命名)
curl -s -X PUT --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_ingest/pipeline/rebue -d "{\"description\":\"rebue相关的微服务\",\"processors\":[{\"grok\":{\"field\":\"data\",\"patterns\":[(?m)^\\|(?<addr>[a-f0-9]{8})\\|%{GREEDYDATA}\\|(?<netty_decode>[\\s\\S]+)\\|$"]}},{\"script\":{\"source\":\"if(ctx?.netty_decode!=null)ctx.data=ctx.netty_decode;\"}}]}"
----

=== 创建filebeat的配置文件
./usr/local/elasticsearch/filebeat/filebeat.docker.yml
[source,bash]
----
filebeat:
  config:
    modules:
      path: ${path.config}/modules.d/*.yml
      reload:
        enabled: false
  autodiscover:
    providers:
      - type: docker
        hints:
          enabled: true

processors:
- add_cloud_metadata: ~

output:
  elasticsearch:
    hosts: ["https://es01:9200","https://es02:9200","https://es03:9200"]
    api_key: "xxxxxxxx:xxxxxxxx"  // <.>
----
<.> 上一步获取的id和api_key，格式为 `id:api_key`

== Kibana

=== 配置